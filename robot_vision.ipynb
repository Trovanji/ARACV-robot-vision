{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f15db2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001A1BDFE8AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
      "Predicted classes:\n",
      "desk (18.59%)\n",
      "pool_table (6.19%)\n",
      "envelope (4.48%)\n"
     ]
    }
   ],
   "source": [
    "import pybullet as p\n",
    "import pybullet_data\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "# Setup directories\n",
    "base_dir = \"E:/UC-12564\"\n",
    "urdf_dir = os.path.join(base_dir, \"urdf\")\n",
    "capture_dir = os.path.join(base_dir, \"captures\")\n",
    "os.makedirs(capture_dir, exist_ok=True)\n",
    "\n",
    "# Connect to PyBullet in DIRECT mode\n",
    "p.connect(p.DIRECT)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "p.resetSimulation()\n",
    "p.setGravity(0, 0, -9.8)\n",
    "p.loadURDF(\"plane.urdf\")\n",
    "\n",
    "# Load objects\n",
    "positions = [(0, 0, 0.1), (0.3, 0, 0.1), (-0.3, 0, 0.1), (0.15, 0.3, 0.1),\n",
    "             (-0.15, -0.3, 0.1), (0.3, -0.3, 0.1), (-0.3, 0.3, 0.1)]\n",
    "shapes = [\"cube\"] * len(positions)\n",
    "\n",
    "for idx, pos in enumerate(positions):\n",
    "    urdf_file = os.path.join(urdf_dir, f\"{shapes[idx]}.urdf\")\n",
    "    if os.path.exists(urdf_file):\n",
    "        try:\n",
    "            p.loadURDF(urdf_file, basePosition=pos)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Could not load {urdf_file}: {e}\")\n",
    "    else:\n",
    "        print(f\"[WARNING] URDF not found: {urdf_file}\")\n",
    "\n",
    "# Capture 10 diverse images\n",
    "for i in range(10):\n",
    "    yaw = i * 36\n",
    "    pitch = -10 + (i % 3) * -20\n",
    "    distance = 0.8 + (i % 2) * 0.3\n",
    "\n",
    "    view_matrix = p.computeViewMatrixFromYawPitchRoll(\n",
    "        cameraTargetPosition=[0.1 * (i % 3), -0.1 * (i % 2), 0.1],\n",
    "        distance=distance,\n",
    "        yaw=yaw,\n",
    "        pitch=pitch,\n",
    "        roll=0,\n",
    "        upAxisIndex=2\n",
    "    )\n",
    "    proj_matrix = p.computeProjectionMatrixFOV(\n",
    "        fov=60, aspect=1.0, nearVal=0.1, farVal=2.0\n",
    "    )\n",
    "\n",
    "    _, _, rgb_img, _, _ = p.getCameraImage(\n",
    "        width=640, height=480,\n",
    "        viewMatrix=view_matrix,\n",
    "        projectionMatrix=proj_matrix\n",
    "    )\n",
    "\n",
    "    img = np.reshape(rgb_img, (480, 640, 4))[:, :, :3]\n",
    "    img_path = os.path.join(capture_dir, f\"cam_{i}.png\")\n",
    "    cv2.imwrite(img_path, img)\n",
    "\n",
    "# Classify first image using MobileNetV2\n",
    "img_path = os.path.join(capture_dir, \"cam_0.png\")\n",
    "model = MobileNetV2(weights=\"imagenet\")\n",
    "img = load_img(img_path, target_size=(224, 224))\n",
    "img_array = img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = preprocess_input(img_array)\n",
    "\n",
    "predictions = model.predict(img_array)\n",
    "decoded = decode_predictions(predictions, top=3)[0]\n",
    "\n",
    "print(\"Predicted classes:\")\n",
    "for pred in decoded:\n",
    "    print(f\"{pred[1]} ({pred[2]*100:.2f}%)\")\n",
    "\n",
    "# Properly disconnect the server at the end\n",
    "p.disconnect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
